{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pulum\\AppData\\Local\\conda\\conda\\envs\\TF_VS_35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Try to find values for W and b to compute Y = W * X + b\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hypothesis is X * W + b\n",
    "hypothesis = X * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.5240757 [2.2086694] [-0.8204183]\n",
      "20 0.19749963 [1.5425726] [-1.0498911]\n",
      "40 0.15214378 [1.4590572] [-1.0260718]\n",
      "60 0.13793252 [1.431959] [-0.9802803]\n",
      "80 0.12527035 [1.4111323] [-0.93444216]\n",
      "100 0.11377248 [1.3917605] [-0.8905487]\n",
      "120 0.103330016 [1.3733445] [-0.84869826]\n",
      "140 0.09384593 [1.3557982] [-0.8088128]\n",
      "160 0.0852324 [1.339077] [-0.7708016]\n",
      "180 0.077409446 [1.3231417] [-0.73457676]\n",
      "200 0.07030449 [1.3079553] [-0.7000544]\n",
      "220 0.06385169 [1.2934824] [-0.66715455]\n",
      "240 0.057991166 [1.2796899] [-0.6358009]\n",
      "260 0.052668482 [1.2665455] [-0.60592055]\n",
      "280 0.047834355 [1.2540188] [-0.57744455]\n",
      "300 0.043443933 [1.2420808] [-0.55030674]\n",
      "320 0.03945647 [1.230704] [-0.5244443]\n",
      "340 0.03583497 [1.2198616] [-0.49979722]\n",
      "360 0.03254589 [1.2095289] [-0.47630855]\n",
      "380 0.029558683 [1.1996818] [-0.4539237]\n",
      "400 0.026845662 [1.1902975] [-0.43259096]\n",
      "420 0.024381692 [1.1813543] [-0.4122609]\n",
      "440 0.022143835 [1.1728313] [-0.3928862]\n",
      "460 0.020111395 [1.1647089] [-0.37442192]\n",
      "480 0.018265488 [1.1569681] [-0.35682544]\n",
      "500 0.016589006 [1.1495912] [-0.340056]\n",
      "520 0.015066399 [1.1425607] [-0.3240746]\n",
      "540 0.01368354 [1.135861] [-0.30884415]\n",
      "560 0.012427595 [1.1294761] [-0.29432958]\n",
      "580 0.011286959 [1.1233914] [-0.28049716]\n",
      "600 0.010250974 [1.1175922] [-0.26731485]\n",
      "620 0.0093101105 [1.1120659] [-0.25475204]\n",
      "640 0.008455598 [1.1067992] [-0.24277969]\n",
      "660 0.0076795183 [1.1017802] [-0.23137005]\n",
      "680 0.0069746594 [1.0969968] [-0.22049649]\n",
      "700 0.0063344887 [1.0924382] [-0.21013395]\n",
      "720 0.0057530794 [1.088094] [-0.20025837]\n",
      "740 0.005225046 [1.0839541] [-0.19084705]\n",
      "760 0.0047454657 [1.0800083] [-0.18187788]\n",
      "780 0.004309911 [1.0762483] [-0.17333023]\n",
      "800 0.0039143264 [1.072665] [-0.1651844]\n",
      "820 0.0035550634 [1.06925] [-0.15742144]\n",
      "840 0.0032287624 [1.0659956] [-0.15002322]\n",
      "860 0.0029324212 [1.062894] [-0.14297271]\n",
      "880 0.002663274 [1.0599382] [-0.13625365]\n",
      "900 0.002418828 [1.0571213] [-0.12985022]\n",
      "920 0.0021968144 [1.0544369] [-0.12374774]\n",
      "940 0.0019951824 [1.0518785] [-0.11793204]\n",
      "960 0.0018120577 [1.0494404] [-0.11238962]\n",
      "980 0.001645743 [1.0471169] [-0.10710771]\n",
      "1000 0.0014946834 [1.0449026] [-0.10207405]\n",
      "1020 0.0013575047 [1.0427924] [-0.097277]\n",
      "1040 0.0012329038 [1.0407815] [-0.09270539]\n",
      "1060 0.001119739 [1.0388646] [-0.08834852]\n",
      "1080 0.0010169634 [1.0370382] [-0.08419646]\n",
      "1100 0.0009236282 [1.0352975] [-0.08023955]\n",
      "1120 0.0008388557 [1.0336386] [-0.07646856]\n",
      "1140 0.00076185976 [1.0320578] [-0.07287483]\n",
      "1160 0.00069193594 [1.0305511] [-0.06944999]\n",
      "1180 0.00062842533 [1.0291153] [-0.06618603]\n",
      "1200 0.0005707424 [1.027747] [-0.06307554]\n",
      "1220 0.0005183577 [1.026443] [-0.06011122]\n",
      "1240 0.00047077882 [1.0252002] [-0.05728619]\n",
      "1260 0.00042757232 [1.024016] [-0.05459397]\n",
      "1280 0.00038832802 [1.0228873] [-0.05202832]\n",
      "1300 0.00035268549 [1.0218118] [-0.04958321]\n",
      "1320 0.00032031728 [1.020787] [-0.04725307]\n",
      "1340 0.0002909205 [1.01981] [-0.04503258]\n",
      "1360 0.00026421706 [1.0188788] [-0.04291615]\n",
      "1380 0.0002399638 [1.0179915] [-0.04089918]\n",
      "1400 0.00021794003 [1.0171461] [-0.03897706]\n",
      "1420 0.00019793648 [1.0163403] [-0.0371453]\n",
      "1440 0.00017976928 [1.0155723] [-0.03539962]\n",
      "1460 0.00016326824 [1.0148405] [-0.03373595]\n",
      "1480 0.0001482833 [1.014143] [-0.03215047]\n",
      "1500 0.000134674 [1.0134784] [-0.03063954]\n",
      "1520 0.00012231166 [1.0128449] [-0.02919955]\n",
      "1540 0.00011108658 [1.0122414] [-0.02782729]\n",
      "1560 0.00010089126 [1.0116659] [-0.02651951]\n",
      "1580 9.163049e-05 [1.0111177] [-0.02527316]\n",
      "1600 8.322011e-05 [1.0105953] [-0.02408545]\n",
      "1620 7.558181e-05 [1.0100973] [-0.0229535]\n",
      "1640 6.864497e-05 [1.0096227] [-0.02187472]\n",
      "1660 6.234398e-05 [1.0091705] [-0.02084666]\n",
      "1680 5.6621895e-05 [1.0087395] [-0.01986698]\n",
      "1700 5.1424246e-05 [1.0083288] [-0.0189333]\n",
      "1720 4.670386e-05 [1.0079373] [-0.01804346]\n",
      "1740 4.2417694e-05 [1.0075643] [-0.01719545]\n",
      "1760 3.852488e-05 [1.0072088] [-0.01638731]\n",
      "1780 3.4988625e-05 [1.00687] [-0.01561718]\n",
      "1800 3.1777046e-05 [1.0065471] [-0.0148832]\n",
      "1820 2.886e-05 [1.0062394] [-0.0141837]\n",
      "1840 2.621177e-05 [1.0059463] [-0.01351713]\n",
      "1860 2.380544e-05 [1.0056667] [-0.01288191]\n",
      "1880 2.1620841e-05 [1.0054005] [-0.01227651]\n",
      "1900 1.9636196e-05 [1.0051466] [-0.01169958]\n",
      "1920 1.7834054e-05 [1.0049047] [-0.01114971]\n",
      "1940 1.6197106e-05 [1.0046743] [-0.01062572]\n",
      "1960 1.4711059e-05 [1.0044547] [-0.01012639]\n",
      "1980 1.3360998e-05 [1.0042454] [-0.00965055]\n",
      "2000 1.21343355e-05 [1.0040458] [-0.00919707]\n",
      "[5.0110054]\n",
      "[2.500915]\n",
      "[1.4968792 3.5049512]\n",
      "--------------------\n",
      "New training data\n",
      "0 1.2035878 [1.0040361] [-0.00917497]\n",
      "20 0.16904518 [1.2656431] [0.13599995]\n",
      "40 0.14761032 [1.2494287] [0.1994607]\n",
      "60 0.1289092 [1.2330987] [0.25843924]\n",
      "80 0.112577364 [1.217833] [0.31355378]\n",
      "100 0.09831472 [1.2035669] [0.36505872]\n",
      "120 0.0858589 [1.1902351] [0.41319057]\n",
      "140 0.07498121 [1.1777765] [0.45817032]\n",
      "160 0.06548168 [1.1661338] [0.50020427]\n",
      "180 0.057185628 [1.1552536] [0.53948534]\n",
      "200 0.049940623 [1.1450859] [0.57619387]\n",
      "220 0.04361353 [1.1355841] [0.6104983]\n",
      "240 0.03808804 [1.1267046] [0.6425562]\n",
      "260 0.033262532 [1.1184065] [0.67251456]\n",
      "280 0.029048437 [1.110652] [0.70051086]\n",
      "300 0.025368217 [1.1034054] [0.7266737]\n",
      "320 0.022154266 [1.0966333] [0.7511231]\n",
      "340 0.019347508 [1.0903047] [0.77397114]\n",
      "360 0.016896317 [1.0843905] [0.7953231]\n",
      "380 0.014755702 [1.0788639] [0.8152765]\n",
      "400 0.012886246 [1.073699] [0.8339233]\n",
      "420 0.011253654 [1.0688723] [0.85134894]\n",
      "440 0.009827888 [1.0643618] [0.8676333]\n",
      "460 0.008582776 [1.0601467] [0.8828512]\n",
      "480 0.0074953884 [1.0562075] [0.89707255]\n",
      "500 0.006545782 [1.0525265] [0.91036254]\n",
      "520 0.005716468 [1.0490865] [0.92278206]\n",
      "540 0.0049922303 [1.0458719] [0.9343882]\n",
      "560 0.004359761 [1.0428677] [0.9452342]\n",
      "580 0.0038074062 [1.0400602] [0.95536995]\n",
      "600 0.0033250246 [1.0374365] [0.9648421]\n",
      "620 0.0029037776 [1.0349848] [0.97369367]\n",
      "640 0.0025359015 [1.0326937] [0.9819654]\n",
      "660 0.002214623 [1.0305526] [0.9896955]\n",
      "680 0.0019340345 [1.0285516] [0.99691963]\n",
      "700 0.00168901 [1.0266818] [1.0036705]\n",
      "720 0.0014750187 [1.0249343] [1.0099791]\n",
      "740 0.0012881459 [1.0233014] [1.0158745]\n",
      "760 0.0011249502 [1.0217754] [1.0213839]\n",
      "780 0.0009824366 [1.0203494] [1.0265325]\n",
      "800 0.00085795636 [1.0190165] [1.031344]\n",
      "820 0.0007492685 [1.0177711] [1.0358404]\n",
      "840 0.0006543382 [1.0166073] [1.0400422]\n",
      "860 0.0005714378 [1.0155196] [1.0439689]\n",
      "880 0.0004990428 [1.0145032] [1.0476384]\n",
      "900 0.0004358191 [1.0135534] [1.0510677]\n",
      "920 0.00038059853 [1.0126659] [1.0542723]\n",
      "940 0.00033238466 [1.0118364] [1.0572668]\n",
      "960 0.00029027028 [1.0110612] [1.0600659]\n",
      "980 0.00025349384 [1.0103369] [1.0626812]\n",
      "1000 0.00022137805 [1.0096596] [1.0651253]\n",
      "1020 0.00019332914 [1.009027] [1.0674093]\n",
      "1040 0.00016882908 [1.0084357] [1.0695443]\n",
      "1060 0.00014743926 [1.0078832] [1.0715389]\n",
      "1080 0.00012875989 [1.0073669] [1.0734029]\n",
      "1100 0.00011244613 [1.0068845] [1.0751448]\n",
      "1120 9.820034e-05 [1.0064336] [1.0767726]\n",
      "1140 8.575572e-05 [1.0060122] [1.0782939]\n",
      "1160 7.489431e-05 [1.0056186] [1.0797151]\n",
      "1180 6.5406595e-05 [1.0052506] [1.0810436]\n",
      "1200 5.7120626e-05 [1.0049067] [1.082285]\n",
      "1220 4.9882394e-05 [1.0045854] [1.0834452]\n",
      "1240 4.3564207e-05 [1.0042851] [1.0845293]\n",
      "1260 3.804614e-05 [1.0040045] [1.0855423]\n",
      "1280 3.3225275e-05 [1.0037422] [1.0864892]\n",
      "1300 2.901571e-05 [1.0034971] [1.087374]\n",
      "1320 2.5340463e-05 [1.0032681] [1.0882009]\n",
      "1340 2.2129901e-05 [1.0030541] [1.0889736]\n",
      "1360 1.9328054e-05 [1.0028542] [1.0896953]\n",
      "1380 1.6878726e-05 [1.0026673] [1.0903702]\n",
      "1400 1.4740454e-05 [1.0024927] [1.0910008]\n",
      "1420 1.2873619e-05 [1.0023293] [1.09159]\n",
      "1440 1.1241735e-05 [1.0021769] [1.0921409]\n",
      "1460 9.818069e-06 [1.0020343] [1.0926555]\n",
      "1480 8.574677e-06 [1.0019011] [1.0931364]\n",
      "1500 7.4886166e-06 [1.0017766] [1.0935858]\n",
      "1520 6.539272e-06 [1.0016603] [1.094006]\n",
      "1540 5.711003e-06 [1.0015516] [1.0943984]\n",
      "1560 4.9874334e-06 [1.00145] [1.0947653]\n",
      "1580 4.3559958e-06 [1.0013549] [1.095108]\n",
      "1600 3.804345e-06 [1.0012664] [1.0954283]\n",
      "1620 3.322312e-06 [1.0011833] [1.0957278]\n",
      "1640 2.9007756e-06 [1.0011058] [1.0960077]\n",
      "1660 2.5334934e-06 [1.0010334] [1.0962691]\n",
      "1680 2.2123513e-06 [1.0009656] [1.0965135]\n",
      "1700 1.9319202e-06 [1.0009024] [1.096742]\n",
      "1720 1.6872369e-06 [1.0008434] [1.0969553]\n",
      "1740 1.4738443e-06 [1.0007881] [1.0971545]\n",
      "1760 1.2871469e-06 [1.0007366] [1.0973408]\n",
      "1780 1.1242403e-06 [1.0006883] [1.0975149]\n",
      "1800 9.815564e-07 [1.0006433] [1.0976776]\n",
      "1820 8.573661e-07 [1.0006013] [1.0978296]\n",
      "1840 7.4871434e-07 [1.000562] [1.0979716]\n",
      "1860 6.5427787e-07 [1.0005252] [1.0981042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880 5.712507e-07 [1.0004908] [1.0982282]\n",
      "1900 4.989224e-07 [1.0004587] [1.0983442]\n",
      "1920 4.358085e-07 [1.0004287] [1.0984526]\n",
      "1940 3.8070743e-07 [1.0004005] [1.0985538]\n",
      "1960 3.3239553e-07 [1.0003743] [1.0986484]\n",
      "1980 2.9042917e-07 [1.00035] [1.0987366]\n",
      "2000 2.5372992e-07 [1.0003271] [1.0988194]\n",
      "[6.1004534]\n",
      "[3.5996385]\n",
      "[2.5993123 4.599964 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit the line\n",
    "    for step in range(2001):\n",
    "        _, cost_val, W_val, b_val = sess.run(\n",
    "            [train, cost, W, b], feed_dict={X: [1, 2, 3], Y: [1, 2, 3]}\n",
    "        )\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n",
    "\n",
    "    # Testing our model\n",
    "    print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))\n",
    "\n",
    "    print(\"--------------------\")\n",
    "    print(\"New training data\")\n",
    "    # Fit the line with new training data\n",
    "    for step in range(2001):\n",
    "        _, cost_val, W_val, b_val = sess.run(\n",
    "            [train, cost, W, b],\n",
    "            feed_dict={X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]},\n",
    "        )\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n",
    "\n",
    "    # Testing our model\n",
    "    print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
